# ğŸ§ Voice-to-Insights Pipeline for Customer Support Calls

This project is an end-to-end AI pipeline that transforms **customer-agent phone calls** into **actionable business insights** using automatic speech recognition (ASR), large language models (LLMs), and retrieval-augmented generation (RAG). It supports **multilingual input** (English, Hindi, Hinglish), **speaker diarization**, **sentiment/tonality/intent analysis**, and **summary generation** with context-aware **follow-up action recommendations**.

---

## ğŸ§© Features

âœ… Transcribe customer support audio recordings using Whisper  
âœ… Diarize speakers (agent vs. customer)  
âœ… Analyze each utterance for:
- **Sentiment** (Positive, Neutral, Negative)
- **Tonality** (e.g., Angry, Polite, Calm)
- **Intent** (e.g., Complaint, Query, Feedback)  
âœ… Summarize full conversations using Gemini LLM  
âœ… Suggest contextual follow-up actions using a RAG pipeline  
âœ… Evaluate transcription, insights, and summaries

---

## ğŸ“ Project Structure

â”œâ”€â”€ audio_processor.py # Audio loading, normalization, silence removal
â”œâ”€â”€ analyzer.py # Sentiment, Tonality, Intent analysis
â”œâ”€â”€ config.py # Centralized configuration and model paths
â”œâ”€â”€ evaluator.py # Metrics: WER, F1, cosine similarity, etc.
â”œâ”€â”€ rag_agent.py # FAISS + Gemini-based follow-up action generator
â”œâ”€â”€ summarizer.py # Gemini-based conversation summarizer
â”œâ”€â”€ transcriber.py # Whisper STT + pyannote diarization
â”œâ”€â”€ utils.py # Helpers: clean folders, generate sample docs
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ documents/ # Sample documents for vector DB (RAG)
â”‚ â”œâ”€â”€ test_audios/ # 3â€“5 sample customer call recordings
â”‚ â””â”€â”€ vector_db/ # FAISS vector DB generated from docs
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ transcription.json # Diarized and transcribed conversation
â”‚ â”œâ”€â”€ analysis.json # Per-utterance sentiment/intent/tonality
â”‚ â”œâ”€â”€ summary.txt # Generated summary
â”‚ â””â”€â”€ followup.txt # Suggested follow-up actions
â””â”€â”€ .env # API keys (not committed)


---

## ğŸš€ Getting Started

### 1. ğŸ”§ Prerequisites

- Python 3.8+
- [HuggingFace account](https://huggingface.co) (for Whisper + pyannote)
- [Google API Key for Gemini](https://ai.google.dev/)
- GPU (recommended for diarization)

Install dependencies:

```bash
pip install -r requirements.txt

.env file (required):

ini
Copy
Edit
HF_TOKEN=your_huggingface_token
GEMINI_API_KEY=your_google_api_key
2. ğŸ™ï¸ Input Requirements
Upload 3â€“5 customer support call recordings to data/test_audios/

Format: WAV or MP3 (mono/stereo, max 5 minutes)

Optional: Add sample FAQs/policies as .txt files in data/documents/

3. ğŸ§ª Run the Pipeline (Example Flow)
python
Copy
Edit
# Step 1: Transcribe and diarize audio
from transcriber import Transcriber
t = Transcriber()
transcription = t.transcribe_with_diarization("data/test_audios/sample.wav")
t.save_transcription(transcription, "outputs/transcription.json")

# Step 2: Analyze sentiments, tonality, and intents
from analyzer import ConversationAnalyzer
analyzer = ConversationAnalyzer()
analysis = analyzer.analyze_conversation(transcription)
summary_stats = analyzer.get_conversation_summary_stats(analysis)

# Step 3: Generate summary
from summarizer import ConversationSummarizer
summarizer = ConversationSummarizer()
summary = summarizer.generate_summary(transcription, summary_stats)

# Step 4: Generate follow-up actions using RAG
from rag_agent import RAGAgent
rag = RAGAgent()
followups = rag.get_followup_actions(summary)

# Save outputs
import json
with open("outputs/analysis.json", "w") as f: json.dump(analysis, f, indent=2)
with open("outputs/summary.txt", "w") as f: f.write(summary)
with open("outputs/followup.txt", "w") as f: f.write(followups)
4. âœ… Evaluation
Evaluate transcription, summary, and insight quality using:

python
Copy
Edit
from evaluator import SystemEvaluator
evaluator = SystemEvaluator()

# Example: Evaluate transcription quality
metrics = evaluator.evaluate_transcription(ground_truth, predicted)
print(metrics)  # {'word_error_rate': ..., 'speaker_accuracy': ...}
ğŸ“Š Models Used
Task	Model
STT	openai/whisper-tiny (via HuggingFace Transformers)
Diarization	pyannote/speaker-diarization
Sentiment	nlptown/bert-base-multilingual-uncased-sentiment
Tonality	bhadresh-savani/bert-base-go-emotion
Intent Detection	MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli
RAG Embeddings	sentence-transformers/all-MiniLM-L6-v2
LLM	gemini-2.0-flash (Google Generative AI)

ğŸ“Œ Highlights
âœ… Multilingual Audio Support: Hindi, English, Hinglish

âœ… Speaker-Aware Transcription: Diarization with time segments

âœ… Zero-shot Intent Analysis

âœ… LLM-Based Summary & Suggestions

âœ… RAG for Realistic, Contextual Responses

ğŸ“š Example Output (Real Sample)
Transcription:
json
Copy
Edit
[
  {
    "speaker": "SPEAKER_00",
    "start": 0.03,
    "end": 23.47,
    "text": "I'm just calling to say I'm absolutely blown away by the camera pro one..."
  }
]
Summary:
sql
Copy
Edit
Ashley Perez called to express overwhelming positive feedback regarding the "camera pro one"...
Follow-up Suggestions:
Send thank you email

Ask for testimonial

Offer discount (optional)

ğŸ§  Future Improvements
Add CLI or Streamlit UI for user-friendly interaction

Support longer recordings with chunked transcription

Integrate automated feedback loop to improve model selection

Add multilingual prompt translation for Gemini

ğŸ“¬ Contact
Developer: Dattatray Bodake
Feel free to reach out via GitHub or LinkedIn for feedback or collaboration.

ğŸ“œ License
This project is for educational and demonstration purposes only. Not intended for production use without further security and compliance checks.

yaml
Copy
Edit

---

Let me know if youâ€™d like:
- A **flow diagram** or architecture visual
- An **auto-run notebook wrapper**
- A version tailored to a **specific company or dataset**

Happy to help you polish this for final submission!
